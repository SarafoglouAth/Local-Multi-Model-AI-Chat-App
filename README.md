# ğŸ¤– Local Multi-Model AI Chat App

A privacy-first, local-first AI chat interface that supports multiple models like **OpenAI GPT**, **Anthropic Claude**, and **Metaâ€™s LLaMA** (future-ready). Attach files, customize prompts, and maintain context â€” all without needing an external backend or cloud DB.

***

## ğŸŒŸ Features

* ğŸ”„ Dropdown to switch between AI models (e.g. GPT-4, Claude, Meta)
* ğŸ“ Attach files to use as context in prompts
* âœï¸ Fully editable prompt input
* ğŸ’¬ Context-aware conversation
* ğŸ–¥ï¸ Runs locally â€” no server, no cloud storage
* ğŸ” Your data, your control

***

## ğŸš€ Getting Started

### 1. Prerequisites

* [Node.js](https://nodejs.org/en/) (v18+ recommended)
* [npm](https://www.npmjs.com/)

### 2. Clone the Repository

```
git clone https://github.com/SarafoglouAth/Local-Multi-Model-AI-Chat-App.git
cd Local-Multi-Model-AI-Chat-App
```

### 3. Install Dependencies

```
npm install
```

***

## ğŸ” Environment Setup: API Keys

Create a `.env` file in the root of your project:

```
touch .env
```

Then add the following (include only what you use):

```
# OpenAI API (for GPT-4, GPT-3.5)
OPENAI_API_KEY=your-openai-api-key

# Anthropic API (for Claude models)
ANTHROPIC_API_KEY=your-anthropic-api-key

# Meta API (if available, optional)
META_API_KEY=your-meta-api-key

```

> âš ï¸ Keep your `.env` file safe and **never commit it to GitHub**.

***

### 4. Run the App

```
npm run dev
```

Visit: [http://localhost:5173](http://localhost:5173/)

***

## ğŸ§  Tech Stack

* **Vite** â€“ Superfast development environment
* **React + TypeScript** â€“ Modern frontend architecture
* **Tailwind CSS** â€“ Styling with utility classes
* **dotenv** â€“ Environment variable handlin

***

## ğŸ“„ License

This project is licensed under the **MIT License**.

&#x20;
