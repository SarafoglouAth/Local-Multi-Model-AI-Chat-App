ğŸ¤– Local Multi-Model AI Chat App
A privacy-first, local-first AI chat interface that supports multiple models like OpenAI GPT, Anthropic Claude, and Metaâ€™s LLaMA (future-ready). Attach files, customize prompts, and maintain context â€” all without needing an external backend or cloud DB.

ğŸŒŸ Features
ğŸ”„ Dropdown to switch between AI models (e.g. GPT-4, Claude, Meta)
ğŸ“ Attach files to use as context in prompts
âœï¸ Fully editable prompt input
ğŸ’¬ Context-aware conversation
ğŸ–¥ï¸ Runs locally â€” no server, no cloud storage
ğŸ” Your data, your control

ğŸš€ Getting Started
1. Prerequisites
Node.js (v18+ recommended)
npm
2. Clone the Repository
3. Install Dependencies

ğŸ” Environment Setup: API Keys
Create a .env file in the root of your project:
Then add the following (include only what you use):
âš ï¸ Keep your .env file safe and never commit it to GitHub.

4. Run the App
Visit: http://localhost:5173

ğŸ§  Tech Stack
Vite â€“ Superfast development environment
React + TypeScript â€“ Modern frontend architecture
Tailwind CSS â€“ Styling with utility classes
dotenv â€“ Environment variable handlin

ğŸ“„ License
This project is licensed under the MIT License.
 
