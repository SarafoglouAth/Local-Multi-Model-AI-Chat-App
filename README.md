🤖 Local Multi-Model AI Chat App
A privacy-first, local-first AI chat interface that supports multiple models like OpenAI GPT, Anthropic Claude, and Meta’s LLaMA (future-ready). Attach files, customize prompts, and maintain context — all without needing an external backend or cloud DB.

🌟 Features
🔄 Dropdown to switch between AI models (e.g. GPT-4, Claude, Meta)
📎 Attach files to use as context in prompts
✏️ Fully editable prompt input
💬 Context-aware conversation
🖥️ Runs locally — no server, no cloud storage
🔐 Your data, your control

🚀 Getting Started
1. Prerequisites
Node.js (v18+ recommended)
npm
2. Clone the Repository
3. Install Dependencies

🔐 Environment Setup: API Keys
Create a .env file in the root of your project:
Then add the following (include only what you use):
⚠️ Keep your .env file safe and never commit it to GitHub.

4. Run the App
Visit: http://localhost:5173

🧠 Tech Stack
Vite – Superfast development environment
React + TypeScript – Modern frontend architecture
Tailwind CSS – Styling with utility classes
dotenv – Environment variable handlin

📄 License
This project is licensed under the MIT License.
 
